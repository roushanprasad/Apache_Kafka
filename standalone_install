======================================= Kafka Standalone Setup ===========================================
Step 1: Firstly, download the kafka (i am using kafka 2.11.1 version)
And extract & move it to destination folder say /home/roushan/kafka_2.11-1.0.0
Note: You may do this with 'root' user or any other user (Prefer other user for production)

Download link -> https://kafka.apache.org/downloads

Use the below command to extract: 
tar -xvzf kafka_2.11.1.0.0.tgz
---------------------------------------------------------------------------------
STEP 2: 
Now go back to the user root folder and open the .bashrc file for editing:

> cd $HOME
> gedit .bashrc

In the .bashrc file, add the following line to the end:
export KAFKA_HOME=/home/roushan/kafka_2.11-1.0.0

Save and close the .bashrc and run "source .bashrc" to update the environment variables. 
------------------------------------------------------------------------------------------

STEP 3: 
Now navigate to the kafka home folder and edit the server.properties in its sub-directory "config" for each kafka unix machine:
> cd $KAFKA_HOME/config
> gedit server.properties

In the server.properties file, 
1) search the line "zookeeper.connect" and change it to the following:
zookeeper.connect=192.168.1.12:2181,192.168.1.13:2181

2) search the line "log.dirs" and change it to the following:
log.dirs=/var/kafka-logs

Save and close the server.properties file 
(192.168.1.12 and 192.168.1.13 are the zookeeper nodes). 

Next we go and create the folder /var/kafka-logs (which will store the topics and partitions data for kafka) with write permissions:
> sudo mkdir /var/kafka-logs
> sudo chmod -R 777 /var/kafka-logs
------------------------------------------------------------------------------------------
STEP 4: Run the zookeeper cluster & Run the kafka cluster
> cd $KAFKA_HOME
> bin/kafka-server-start.sh config/server.properties

-------------------------------------------------------------------------------------------
STEP 5: Verifications
To start testing kafka setup, Ctrl+Alt+T to open a new terminal and run the following command to create a topic "verification-topic" 
(a topic is a named entity in kafka which contain one or more partitions which are message queues that can run in parallel and 
serialize to individual folder in /var/kafka-log folder):
> cd $KAKFA_HOME
> bin/kafka-topics.sh --create --zookeeper 192.168.1.12:2181 --topic verification-topic --partitions 1 --replication-factor 1

General Form of above CLI: 
bin/kafka-topics.sh --create --zookeeper <zookeeperhost/ip:port> --topic <topic Name> --partitions <any number> --replication-factor <any Number>


The above command creates a topic named "verification-topic" which contains 1 partition (and with no replication, i.e only 1 copy of topic) 
Also, 192.168.1.12:2181 is the ip:client port of one of the zookeeper server

Now we can check the list of topics in kafka by running the following command:
> bin/kafka-topics.sh --zookeeper 192.168.1.12:2181 --list

To test the producer and consumer interaction in kafka, fire up the console producer by running
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic verification-topic

9092 is the default port for a kafka broker node (which is localhost at the moment). Now the terminal enter interaction mode. 

Let's open another terminal and run the console consumer:
> bin/kafka-console-consumer.sh --zookeeper 192.168.1.12:2181 --topic verification-topic

Now enter some data in the console producer terminal and you should see the data immediately display in the console consumer terminal.

!!!!!!!!!! COngratulations, You are done !!!!!!!
======================================================================================================================
